#11 fireplace 관련; Fireplaces: Number of fireplaces, FireplaceQu: Fireplace quality -fireplace가 있어야 품질이 있지
which((combined.data$Fireplaces > 0) & (is.na(combined.data$FireplaceQu))) ##fireplace가 있는데, qu가 na처리된 것은 없다! 모두 fireplace가 없는것 
combined.data$FireplaceQu[is.na(combined.data$FireplaceQu)] = 'None'
##확인 - FireplaceQu 관련 항목 n/a값 = 없음으로 처리 /data설명 
sort(colSums(sapply(combined.data[n.a_column], is.na)), decreasing = TRUE)
#12 Alley 관련 ; data설명에서 N/A는 alley 접근 어려운 곳이라고 함 
combined.data$Alley[is.na(combined.data$Alley)] = 'None'
##확인 - Alley 관련 항목 n/a값 = 없음으로 처리 /data설명 
sort(colSums(sapply(combined.data[n.a_column], is.na)), decreasing = TRUE)
###############N/A 최종 확인 
sum(is.na(combined.data))
dim(combined.data)
num_features <- names(which(sapply(combined.data, is.numeric)))
cat_features <- names(which(sapply(combined.data, is.character)))
numberic.data <- combined.data[num_features]  #수치형자료만을 가지고 만든 데이터 
#####팩터화 
##qual 열은 모두 none, po,fa,ta,gd,ex로 구성-> 카테고리로 분류 
# 11.22 poolqc, BsmtCond 추가
qual.cols <- c('ExterQual', 'ExterCond', 'GarageQual', 'GarageCond', 'FireplaceQu', 'KitchenQual', 'HeatingQC', 'BsmtQual', 'BsmtCond','PoolQC')
qual.list <- c('None' = 0, 'Po' = 1, 'Fa' = 2, 'TA' = 3, 'Gd' = 4, 'Ex' = 5)
map <- function(cols, list, df){
  for (i in cols){
    df[i] <- as.numeric(list[combined.data[,i]])
  }
  return(df)
}   ##cols의 i 에 데이터의 i열을 수치형변수로 리스트한 df를 만들어라 
numberic.data <- map(qual.cols, qual.list, numberic.data) #각각대응
####Bsmtexposure 팩터화 
table(combined.data$BsmtExposure)
group.prices('BsmtExposure')
bsmt.list <- c('None' = 0, 'No' = 1, 'Mn' = 2, 'Av' = 3, 'Gd' = 4)  #bsmt의 경우 이렇게 점수 부여
numberic.data <- map(c('BsmtExposure'), bsmt.list, numberic.data)
#####bsmtfintype 팩터화 변수설명 참고 
table(combined.data$BsmtFinType1)
table(combined.data$BsmtFinType2)
bsmt.fin.list <- c('None' = 0, 'Unf' = 1, 'LwQ' = 2,'Rec'= 3, 'BLQ' = 4, 'ALQ' = 5, 'GLQ' = 6)
numberic.data <- map(c('BsmtFinType1','BsmtFinType2'), bsmt.fin.list, numberic.data)
## functional 팩터화 
functional.list <- c('None' = 0, 'Sal' = 1, 'Sev' = 2, 'Maj2' = 3, 'Maj1' = 4, 'Mod' = 5, 'Min2' = 6, 'Min1' = 7, 'Typ'= 8)
numberic.data <- map('Functional', functional.list, numberic.data)
## garage 팩터화 
table(combined.data$GarageFinish)
garage.fin.list <- c('None' = 0,'Unf' = 1, 'RFn' = 1, 'Fin' = 2)
numberic.data <- map('GarageFinish', garage.fin.list, numberic.data)
## fence 팩터화
table(combined.data$Fence)
fence.list <- c('None' = 0, 'MnWw' = 1, 'GdWo' = 1, 'MnPrv' = 2, 'GdPrv' = 4)
numberic.data <- map('Fence', fence.list, numberic.data)
# 2918   52
library(plyr)
## MSZoning
table(combined.data$MSZoning)
aggregate(SalePrice~MSZoning, train, mean)
zoning.list <- c('C (all)' = 0, 'RH' = 1, 'FV' = 2, 'RM' = 3, 'RL' = 4)
numberic.data <- map('MSZoning', zoning.list, numberic.data)
sum(is.na(numberic.data$MSZoning))
## LotShape
table(combined.data$LotShape)
aggregate(SalePrice~LotShape, train, mean)
char.list <- c('IR3' = 2, 'IR2' = 3, 'IR1' = 1, 'Reg' = 0)
numberic.data <- map('LotShape', char.list, numberic.data)
## LandContour
table(combined.data$LandContour)
aggregate(SalePrice~LandContour, train, mean)
char.list <- c('Low' = 3, 'Bnk' = 1, 'HLS' = 4, 'Lvl' = 2)
numberic.data <- map('LandContour', char.list, numberic.data)
#drop
col.drops <- c('Utilities')
numberic.data <- numberic.data[,!names(numberic.data) %in% c('Utilities')]
## LotConfig
table(combined.data$LotConfig)
aggregate(SalePrice~LotConfig, train, mean)
char.list <- c('FR3' = 4, 'FR2' = 2, 'CulDSac' = 5, 'Corner' = 3, 'Inside' = 1)
numberic.data <- map('LotConfig', char.list, numberic.data)
## LandSlope
table(combined.data$LandSlope)
aggregate(SalePrice~LandSlope, train, mean)
char.list <- c('Sev' = 3, 'Mod' = 2, 'Gtl' = 1)
numberic.data <- map('LandSlope', char.list, numberic.data)
## Neighborhood  # 가격별로 아주좋음(4) 좋음(3) 보통(2) 나쁨(1) 별로(0)
table(combined.data$Neighborhood)
aggregate(SalePrice~Neighborhood, train, mean)
char.list <- c('MeadowV' = 0, 'IDOTRR' = 1, 'Sawyer' = 1, 'BrDale' = 1, 'OldTown' = 1, 'Edwards' = 1, 
               'BrkSide' = 1, 'Blueste' = 1, 'SWISU' = 2, 'NAmes' = 2, 'NPkVill' = 2, 'Mitchel' = 2,
               'SawyerW' = 2, 'Gilbert' = 2, 'NWAmes' = 2, 'Blmngtn' = 2, 'CollgCr' = 2, 'ClearCr' = 3, 
               'Crawfor' = 3, 'Veenker' = 3, 'Somerst' = 3, 'Timber' = 3, 'StoneBr' = 4, 'NoRidge' = 4, 
               'NridgHt' = 4)
numberic.data <- map('Neighborhood', char.list, numberic.data)
## Condition1
table(combined.data$Condition1)
aggregate(SalePrice~Condition1, train, mean)
char.list <- c('RRAe'=1, 'Feedr'=2, 'Artery'=3, 'Norm'=4, 'RRAn'=5,'RRNn'=6, 'RRNe'=7, 'PosN'=8, 'PosA'=9)
numberic.data <- map('Condition1', char.list, numberic.data)
## Condition2
table(combined.data$Condition2)
aggregate(SalePrice~Condition2, train, mean)
char.list <- c('RRAe'=1, 'Feedr'=2, 'Artery'=3, 'Norm'=4, 'RRAn'=5,'RRNn'=6, 'RRNe'=7, 'PosN'=8, 'PosA'=9)
numberic.data <- map('Condition2', char.list, numberic.data)
## BldgType 
table(combined.data$BldgType)
aggregate(SalePrice~BldgType, train, mean)
char.list <- c('1Fam'=5, '2fmCon'=1, 'Duplex'=3,  'Twnhs'=2, 'TwnhsE'=4) 
numberic.data <- map('BldgType', char.list, numberic.data)
## HouseStyle  # 가격별로 높->낮(1) 
table(combined.data$HouseStyle)
aggregate(SalePrice~HouseStyle, train, mean)
char.list <- c('1.5Fin'=2, '1.5Unf'=1, '1Story'=3, '2.5Fin'=4, '2.5Unf'=2, '2Story'=4, 'SFoyer'=1, 'SLvl'=3)
numberic.data <- map('HouseStyle', char.list, numberic.data)
## RoofStyle  # 가격별 1~3
table(combined.data$RoofStyle)
aggregate(SalePrice~RoofStyle, train, mean)
char.list <- c('Flat'=3,'Gable'=2, 'Gambrel'=1, 'Hip'=3,  'Mansard'=2, 'Shed'=1)
numberic.data <- map('RoofStyle', char.list, numberic.data)
## RoofMatl # 가격별 1~4
table(combined.data$RoofMatl)
aggregate(SalePrice~RoofMatl, train, mean)
char.list <- c('ClyTile'=1, 'CompShg'=2, 'Membran'=4, 'Metal'=2, 'Roll'=1, 'Tar&Grv'=3, 'WdShake'=3, 'WdShngl'=4)
numberic.data <- map('RoofMatl', char.list, numberic.data)
## Exterior1st # 가격별 1~4
table(combined.data$Exterior1st)
aggregate(SalePrice~Exterior1st, train, mean)
char.list <- c('AsbShng'=1, 'AsphShn'=1, 'BrkComm'=2, 'BrkFace'=3,  'CBlock'=4, 'CemntBd'=4,
               'HdBoard'=2, 'ImStucc'=2, 'MetalSd'=1, 'Other'=4, 'Plywood'=3, 'Stone'=2,  
               'Stucco'=3, 'VinylSd'=3, 'Wd Sdng'=1, 'WdShing'=3) 
numberic.data <- map('Exterior1st', char.list, numberic.data)
## Exterior2nd
table(combined.data$Exterior2nd)
aggregate(SalePrice~Exterior2nd, train, mean)
char.list <- c('AsbShng'=1, 'AsphShn'=1, 'Brk Cmn'=2, 'BrkFace'=3,  'CBlock'=4, 'CmentBd'=4,
               'HdBoard'=2, 'ImStucc'=2, 'MetalSd'=1, 'Other'=4, 'Plywood'=3, 'Stone'=2,  
               'Stucco'=3, 'VinylSd'=3, 'Wd Sdng'=1, 'Wd Shng'=3)
numberic.data <- map('Exterior2nd', char.list, numberic.data)
sum(is.na(numberic.data$Exterior2nd))
## MasVnrType
table(combined.data$MasVnrType)
aggregate(SalePrice~MasVnrType, train, mean)
char.list <- c('BrkCmn'=1, 'BrkFace'=2, 'None'=0, 'Stone'=3) 
numberic.data <- map('MasVnrType', char.list, numberic.data)
## Foundation  # 가격별 1~3
table(combined.data$Foundation)
aggregate(SalePrice~Foundation, train, mean)
char.list <- c('BrkTil'=2, 'CBlock'=2, 'PConc'=3, 'Slab'=1,'Stone'=3,'Wood'=1) 
numberic.data <- map('Foundation', char.list, numberic.data)
## Heating  # 가격별 1~3
table(combined.data$Heating)
aggregate(SalePrice~Heating, train, mean)
char.list <- c('Floor'=2, 'GasA'=2,  'GasW'=3, 'Grav'=1,'OthW'=3, 'Wall'=1)
numberic.data <- map('Heating', char.list, numberic.data)
## CentralAir
table(combined.data$CentralAir)
aggregate(SalePrice~CentralAir, train, mean)
char.list <- c('N'=0,'Y'=1)
numberic.data <- map('CentralAir', char.list, numberic.data)
## Electrical
aggregate(SalePrice~Electrical, train, mean)
char.list <- c('Mix' = 1, 'FuseP' = 2, 'FuseF' = 3, 'FuseA' = 4, 'SBrkr'=5)
numberic.data <- map('Electrical', char.list, numberic.data)
## GarageType
aggregate(SalePrice~GarageType, train, mean)
char.list <- c('None' = 0, 'CarPort' = 1, '2Types' = 2, 'Basment' = 2, 'BuiltIn' = 3, 'Detchd' = 1, 'Attchd' = 3)
numberic.data <- map('GarageType', char.list, numberic.data)
head(numberic.data$GarageType)
sum(is.na(numberic.data$GarageType))
## MiscFeature # 가격별 1~4
aggregate(SalePrice~MiscFeature, train, mean)
char.list <- c('None' = 0, 'TenC' = 4, 'Othr' = 1, 'Gar2' = 3, 'Shed' = 2)
numberic.data <- map('MiscFeature', char.list, numberic.data)
## SaleType # 가격별 1~3
table(combined.data$SaleType)
aggregate(SalePrice~SaleType, train, mean)
char.list <- c('Con' = 3, 'Oth' = 1, 'ConLw' = 1, 'WD'=2, 'COD'=2,
               'ConLI' = 2, 'CWD' = 3, 'ConLD' = 1, 'New'=3)
numberic.data <- map('SaleType', char.list, numberic.data)
sum(is.na(numberic.data$SaleType))
## SaleCondition  # 다른 사람 참고
aggregate(SalePrice~SaleCondition, train, mean)
char.list <- c('Abnorml'=1, 'Alloca'=2, 'AdjLand'=3, 'Family'=4, 'Normal'=5, 'Partial'= 0)
numberic.data <- map('SaleCondition', char.list, numberic.data)
#### ONEHOT
## Street 
table(combined.data$Street)
char.list <- c('Pave' = 0, 'Grvl' = 1)
numberic.data <- map('Street', char.list, numberic.data)
## Alley
char.list <- c('None' = 0, 'Pave' = 0, 'Grvl' = 1)
numberic.data <- map('Alley', char.list, numberic.data)
## PavedDrive # what does it mean?
aggregate(SalePrice~PavedDrive, train, mean)
char.list <- c('P' = 0, 'N' = 0, 'Y' = 1)
numberic.data <- map('PavedDrive', char.list, numberic.data)
## MSdwelling 팩터화
# 오류의 주범 (아래)
numberic.data$MSSubClass <- as.factor(numberic.data$MSSubClass)
numberic.data$MSSubClass <- revalue(numberic.data$MSSubClass, c('20' = 1, '30' = 0, '40' = 0, 
                                                                '45' = 0,'50' = 0, '60' = 1, '70' = 0, '75' = 0, '80' = 0, '85' = 0, '90' = 0, 
                                                                '120' = 1, '150' = 0, '160' = 0, '180' = 0, '190' = 0))
numberic.data$MSSubClass <- as.numeric(gsub("2","0",numberic.data$MSSubClass))
numberic.data$MSSubClass <- as.numeric(numberic.data$MSSubClass)  # 1 아니면 2로 바뀜
sum(is.na(numberic.data$MSSubClass))
#### CHECK
dim(numberic.data)  # 2918 79 util 빼면 78
##데이터 합치기/처음에 rbind로 train부터 했기때문에 이렇게 뽑아내기 가능 
##training data 추출
train.data <- cbind(numberic.data[1:1460,], train['SalePrice'])   
head(train.data)  
test.data <- cbind(numberic.data[1461:2919,])   
sum(is.na(numberic.data))
#### Data Preprocessing
all_data <- numberic.data
# transform SalePrice target to log form
train$SalePrice <- log(train$SalePrice + 1)
# for numeric feature with excessive skewness, perform log transformation
# first get data type for each feature
feature_classes <- sapply(names(all_data),function(x){class(all_data[[x]])})
numeric_feats <-names(feature_classes[feature_classes != "character"])
num_features <- names(which(sapply(all_data, is.numeric)))
cat_features <- names(which(sapply(all_data, is.character)))
# get names of categorical features
categorical_feats <- names(feature_classes[feature_classes == "character"])
library(timeDate)
# determine skew for each numeric feature
num_features <- names(which(sapply(all_data, is.numeric)))
skewed_feats <- sapply(num_features, function(x){skewness(all_data[[x]],na.rm=TRUE)})
# keep only features that exceed a threshold for skewness
skewed_feats <- skewed_feats[skewed_feats > 0.75]
# transform excessively skewed features with log(x + 1)
for(x in names(skewed_feats)) {
  all_data[[x]] <- log(all_data[[x]] + 1)
}
# 이것 때문인가? categori 에러
col.drops <- c('Utilities')
character.data <- character.data[,!names(numberic.data) %in% c('Utilities')]
# get names of categorical features
categorical_feats <- names(feature_classes[feature_classes == "character"])
dim(train)
dim(test)
dim(all_data)
X_train <- all_data[1:nrow(train),]
X_test <- all_data[(nrow(train)):nrow(all_data),]
#train)+1??
y <- train$SalePrice  #y는 column이 아니라 숫자여야함
X_train$SalePrice<-y
#####jaeyoung modeling#####
colSums(is.na(X_train))
#1modeling-stepwise
library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(12)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
#both <- predict(b2, newdata=X_test)
rmse(obs, both)
ID<-data.frame(test$Id)
#head(X_test)
#head(ID)
testdata<-cbind(ID,X_test)
##prediction
bothpredict <- predict(b2, testdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
#rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
rmse(obs, both)
rmse(obs, bothpredict)
rmse(bothpredict)
set.seed(20)
colSums(is.na(X_train))
#1modeling-stepwise
library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(20)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
#both <- predict(b2, newdata=X_test)
rmse(obs, both)
all_data <- numberic.data
X_train <- all_data[1:nrow(train),]
X_test <- all_data[(nrow(train)):nrow(all_data),]
#train)+1??
y <- train$SalePrice  #y는 column이 아니라 숫자여야함
X_train$SalePrice<-y
################################################전처리완료 
#####jaeyoung modeling#####
colSums(is.na(X_train))
#1modeling-stepwise
#library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(20)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
na(X_train))
#1modeling-stepwise
#library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(12)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
#both <- predict(b2, newdata=X_test)
rmse(obs, both)
all_data <- numberic.data
l_data[1:nrow(train),]
X_test <- all_data[(nrow(train)):nrow(all_data),]
#train)+1??
y <- train$SalePrice  #y는 column이 아니라 숫자여야함
X_train$SalePrice<-y
################################################전처리완료 
#####jaeyoung modeling#####
colSums(is.na(X_train))
#1modeling-stepwise
#library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(12)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
#both <- predict(b2, newdata=X_test)
rmse(obs, both)
# transform SalePrice target to log form
train$SalePrice <- log(train$SalePrice + 1)
# for numeric feature with excessive skewness, perform log transformation
# first get data type for each feature
feature_classes <- sapply(names(all_data),function(x){class(all_data[[x]])})
numeric_feats <-names(feature_classes[feature_classes != "character"])
num_features <- names(which(sapply(all_data, is.numeric)))
cat_features <- names(which(sapply(all_data, is.character)))
# get names of categorical features
categorical_feats <- names(feature_classes[feature_classes == "character"])
library(timeDate)
# determine skew for each numeric feature
num_features <- names(which(sapply(all_data, is.numeric)))
skewed_feats <- sapply(num_features, function(x){skewness(all_data[[x]],na.rm=TRUE)})
# keep only features that exceed a threshold for skewness
skewed_feats <- skewed_feats[skewed_feats > 0.75]
# transform excessively skewed features with log(x + 1)
for(x in names(skewed_feats)) {
  all_data[[x]] <- log(all_data[[x]] + 1)
}
# 이것 때문인가? categori 에러
col.drops <- c('Utilities')
character.data <- character.data[,!names(numberic.data) %in% c('Utilities')]
# get names of categorical features
categorical_feats <- names(feature_classes[feature_classes == "character"])
dim(train)
dim(test)
dim(all_data)
X_train <- all_data[1:nrow(train),]
X_test <- all_data[(nrow(train)):nrow(all_data),]
#train)+1??
y <- train$SalePrice  #y는 column이 아니라 숫자여야함
X_train$SalePrice<-y
colSums(is.na(X_train))
#1modeling-stepwise
#library(leaps)
a<-lm(SalePrice~.,data=X_train)
summary(a)
set.seed(12)
b2<-step(a,direction='both')
summary(b2)
##########rmse 구하기 
install.packages('Metrics')
library(Metrics)
obs <- X_train$SalePrice
both <- predict(b2, newdata=X_train)
#both <- predict(b2, newdata=X_test)
rmse(obs, both)
가 
ID<-data.frame(test$Id)
#head(X_test)
#head(ID)
testdata<-cbind(ID,X_test)
##prediction
bothpredict <- predict(b2, testdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
write.csv(prediction, file = 'predict.csv', row.names = F)
summary(a)
X_train <- all_data[1:nrow(train),]
X_test <- all_data[(nrow(train)+1):nrow(all_data),]
train$SalePrice <- log(train$SalePrice + 1)  # 중요
y <- train$SalePrice
# caret 패키지를 이용한 model training parameters 설정하기
tcr <- trainControl(method="repeatedcv",
                                 number=5,
                                 repeats=5,
                                 verboseIter=FALSE)
# 데이터의 구조를 확인, 문자형 들어가면 오류남
str(all_data)  # 다 num 아니면 int
#### Ridge 회귀 모델
# alpha가 0일 때, Ridge regression
lambdas <- seq(1,0,-0.001)
# train model
set.seed(123)  # for reproducibility
model_ridge <- train(x=X_train, y=y,
                     method="glmnet",
                     preProcess ="medianImpute",
                     metric="RMSE",
                     maximize=FALSE,
                     trControl=tcr,
                     tuneGrid=expand.grid(alpha=0,
                                          lambda=lambdas))
# alpha가 1일 때, Lasso regression
# train model
set.seed(123)  # for reproducibility
model_lasso <- train(x=X_train,y=y,
                     method="glmnet",
                     preProcess ="medianImpute",
                     metric="RMSE",
                     maximize=FALSE,
                     trControl=tcr,
                     tuneGrid=expand.grid(alpha=1,
                                          lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
                                                   0.00075,0.0005,0.0001)))
ID<-data.frame(test$Id)
#head(X_test)
#head(ID)
testdata<-cbind(ID,X_test)
##prediction
bothpredict <- predict(b2, testdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
write.csv(prediction, file = 'predict.csv', row.names = F)
##prediction
set.seed(123)  # for reproducibility
model_lasso <- train(x=X_test,y=y,
                     method="glmnet",
                     preProcess ="medianImpute",
                     metric="RMSE",
                     maximize=FALSE,
                     trControl=tcr,
                     tuneGrid=expand.grid(alpha=1,
                                          lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
                                                   0.00075,0.0005,0.0001)))
model_lasso <- train(x=X_train,y=y,
                     method="glmnet",
                     preProcess ="medianImpute",
                     metric="RMSE",
                     maximize=FALSE,
                     trControl=tcr,
                     tuneGrid=expand.grid(alpha=1,
                                          lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
                                                   0.00075,0.0005,0.0001)))
## end 
estdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
write.csv(prediction, file = 'predict.csv', row.names = F)
ID<-data.frame(test$Id)
testdata<-cbind(ID,X_test)
##prediction
bothpredict <- predict(b2, testdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
write.csv(prediction, file = 'predict.csv', row.names = F)
ID<-data.frame(test$Id)
testdata<-cbind(ID,X_test)
##prediction
bothpredict <- predict(b2, testdata)
bothpredict <- exp(bothpredict)
head(bothpredict)
rmse(obs, both)
## end 
prediction <- data.frame(ID=testdata$test.Id, SalePrice = bothpredict)
head(prediction)
write.csv(prediction, file = 'predict.csv', row.names = F)
q()
